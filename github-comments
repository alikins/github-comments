#!/usr/local/bin/python

# show github pull request comments in a lint like format
#
# ala, pep8, jslint, etc, except for code review comments
#
# potentially useful to use with syntastic/flymake/etc
#
# Thoughts:
#   - it would be nice if this was a minimal dep one file script
#   - it would be nice if this could DWIM and find the approriate
#     pull requests automatically
#   - initial use case is "I have a local branch, that I've pushed
#     to github, and isssued a pull request. I would like to see
#     the per line code review comments for that pull request"
#   - may eventually also support showing comments for arbitrary
#     pull requests. for example, if you are reviewing a pull
#     request, you could see the comments other have made
#   - unsure what to do with the primary comments view...
#     - anything that references a file could get it as a per file
#       comment
#     - at least tools like vim makeprg/errorformat/quicklist/make
#       can deal with per project/branch config
#   - it is a little tricky figuring out what the right pull request
#     is, especially if local/remote ref names dont match, and there is
#     no tracking branch. Should be able to find it by tracking donw
#     the right sha's though

from hashlib import md5
# we could ditch the git subprocess probably
import ConfigParser
import operator
import os
import re
import subprocess
import sys
import types

# for parsing html into plain txt
from BeautifulSoup import BeautifulSoup
# for parsing markdown into html, since the comments use it
import markdown
# for http, though curl or even urllib will be okay
# if we stick to a single file util concept
import requests

# from from https://gist.github.com/gasman/856894
# git hub api comment content types stuff doesnt work
# bundle here for lower deps, since it seems that
#
# https://github.com/github/developer.github.com/commit/b6a782f74a4c1a1a28d3ac2bfddbea6f6ae4223c
# seems to imply it was removed
#

# regex for parsing a diff hunk header and finding the offsets and sizes
diff_hunk_pattern = re.compile("^@@ -(\\d+),(\\d+) \\+(\\d+),(\\d+) @@")

DEBUG = False

cfg = None

class PullRequest(object):
    def __init__(self, repo_owner, repo_name,
                 pr_number, diffs=None):
        self.repo_owner = repo_owner
        self.repo_name = repo_name
        self.pr_number = pr_number
        self.diffs = diffs

    @classmethod
    def create_by_number(cls, repo_owner, repo_name, pr_number):
        url = "htps://api.github.com/repos/%s/%s/pulls/%s" % (repo_owner,
                                                              repo_name,
                                                              pr_number)
        pr = get_url(url, auth=get_auth())
        return cls(repo_owner, repo_name, pr['number'])


class PullRequestList(object):
    def __init__(self):
        self.prs = []

    def find_prs_for_ref(self, repo_owner, repo_name, remote_ref_name):
        """Get all pull request for repo, and filter based on remote_ref_name"""

        # need repo_owner and repo_name to ask for the pull requests
        # TODO: cli arg to check closed pr's as well
        url = "https://api.github.com/repos/%s/%s/pulls?open" % (repo_owner, repo_name)
        prs = get_url(url, auth=get_auth())


        for pr in prs:
            # find the pull request that has match ref name
            if pr['head']['ref'] == u'%s' % remote_ref_name:
                # for the case of a specific pr, we could maybe
                # figure out the file_to_diff locally, but asking
                # the api for it means we dont need to be i a repo
                file_to_diff = compare_commits(repo_owner, repo_name,
                                               pr['base']['sha'],
                                               pr['head']['sha'])
                self.prs.append(PullRequest(repo_owner, repo_name,
                                            pr['number'],
                                            file_to_diff))

    def add_pr_by_number(self, repo_owner, repo_name, pr_number):
        pr = PullRequest.create_by_number(repo_owner, repo_name, pr_number)
        file_to_diff = compare_commits(repo_owner, repo_name,
                                       pr['base']['sha'],
                                       pr['head']['sha'])
        pr.diffs = file_to_diff
        self.prs.append(pr)


def gfm(text):
    # Extract pre blocks.
    extractions = {}

    def pre_extraction_callback(matchobj):
        digest = md5(matchobj.group(0)).hexdigest()
        extractions[digest] = matchobj.group(0)
        return "{gfm-extraction-%s}" % digest
    pattern = re.compile(r'<pre>.*?</pre>', re.MULTILINE | re.DOTALL)
    text = re.sub(pattern, pre_extraction_callback, text)

    # Prevent foo_bar_baz from ending up with an italic word in the middle.
    def italic_callback(matchobj):
        s = matchobj.group(0)
        if list(s).count('_') >= 2:
            return s.replace('_', '\_')
        return s
    pattern = re.compile(r'^(?! {4}|\t)\w+(?<!_)_\w+_\w[\w_]*', re.MULTILINE | re.UNICODE)
    text = re.sub(pattern, italic_callback, text)

    # In very clear cases, let newlines become <br /> tags.
    def newline_callback(matchobj):
        if len(matchobj.group(1)) == 1:
            return matchobj.group(0).rstrip() + '  \n'
        else:
            return matchobj.group(0)
    pattern = re.compile(r'^[\w\<][^\n]*(\n+)', re.MULTILINE | re.UNICODE)
    text = re.sub(pattern, newline_callback, text)

    # Insert pre block extractions.
    def pre_insert_callback(matchobj):
        return '\n\n' + extractions[matchobj.group(1)]
    text = re.sub(r'{gfm-extraction-([0-9a-f]{32})\}', pre_insert_callback, text)

    return text


# I love regular expressions as much as the next guy, but
# sometimes I just dont want to use them
def find_github_repos():
    """Find remotes that are github, and find the repo name"""
    process = subprocess.Popen(['/usr/bin/git', 'config', '-l'], stdout=subprocess.PIPE)
    git_config = process.communicate()[0]
    config_lines = git_config.splitlines()
    github_repos = set()
    for config_line in config_lines:
        if not config_line.startswith("remote."):
            continue
        key, value = config_line.split('=', 1)
        if not key.endswith('.url'):
            continue
        # verify this is a github repo
        if 'github.com' not in value:
            continue
        repo_url = value
        if repo_url.startswith("git@"):
            repo_url_parts = repo_url.rsplit('/', 1)
            name_dot_git = repo_url_parts[-1]
            owner_name = repo_url_parts[-2].split(':', 1)[1]
        elif repo_url.startswith("git://"):
            repo_url_parts = repo_url.split('/')
            name_dot_git = repo_url_parts[-1]
            # can repo's have / in the name?
            owner_name = repo_url_parts[-2]

        # probably sombody with a foo.git/ reponame
        if name_dot_git.endswith('.git'):
            name = name_dot_git[:-4]
        else:
            name = name_dot_git
        github_repos.add((owner_name, name))
    return github_repos


def get_branch_ref():
    # we could just read and parse .git/HEAD
    # needs to follow through to get upstream branch name
    # see "remote-ref" alias in my gitconfig for example
    process = subprocess.Popen(['/usr/bin/git', 'rev-parse', '--abbrev-ref', 'HEAD'], stdout=subprocess.PIPE)
    this_branch = process.communicate()[0]
    return this_branch.strip()


def get_remote_branch_ref(local_ref):
    # see if we have an "upstream" or merge ref
    branch_config_key = "branch.%s.merge" % local_ref
    process = subprocess.Popen(['/usr/bin/git', 'config', '--get', branch_config_key],
                               stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    remote_merge_ref_full = process.communicate()[0]
    remote_merge_ref_full.strip()

    if process.returncode > 0:
        sys.stderr.write("No merge ref found for %s\n (no config set for %s) " %
                        (local_ref, branch_config_key))
        return local_ref
    # needs to skip remote name here as well
    remote_ref = remote_merge_ref_full[len('refs/heads/'):]
    return remote_ref.strip()

def compare_commits(repo_owner, repo_name, base_sha1, head_sha1):
    url = "https://api.github.com/repos/%s/%s/compare/%s...%s" % \
            (repo_owner, repo_name, base_sha1, head_sha1)
    results = get_url(url, auth=get_auth())
    file_to_diff = {}
    for file_data in results['files']:
        if file_data['filename'] in file_to_diff:
            print "ugh, wtf"
        file_to_diff[file_data['filename']] = file_data['patch']

    return file_to_diff

import pprint
pp = pprint.pprint


# given comment object, figure out which lines of the
# new file the comment corresponds to. Involves a little
# of parsing a diff (reading the hunk header, and keeping
# track of insertions and deletions)
def find_comment_line(comment, pull_request):
    """returns line of latest version of file that comment applies to.

    Returns an int linenumber if the comment applies, None
    otherwise
    """
    op = int(comment['original_position'])
    if comment['position']:
        p = int(comment['position'])
    else:
        # outdated diff
        return None

    diff_hunk = pull_request.diffs[comment['path']]
    diff_hunk_lines = diff_hunk.splitlines()
    # The position index is against the full diff, not just the hunk
    # but we want to compute final line. new approach...
    # - go to 'position' offset, then count backwards till we hit
    # a chunk header, then parse the header line to find this chunks
    # "new_start" line. Then comment_line = new_start + distance_from_p_to_header

    count = 0
    for line in reversed(diff_hunk_lines[:p]):
        # we found a header line
        if line[:2] == "@@":
            matches = diff_hunk_pattern.match(line)
            if matches:
                groups = matches.groups()
                new_start = groups[2]
                new_size = groups[3]
                break
            else:
                continue
        # dont count '-' lines
        if line[0] in ['+', ' ']:
            count += 1
    comment_line = int(new_start) + count
    return comment_line


# support github api pagination
def get_url(url, auth):
    r = requests.get(url, auth=auth)
    if DEBUG:
        sys.stderr.write("%s:%s\n" % (url, r.status_code))
    if 'next' in r.links:
        next_data = get_url(r.links['next']['url'], auth=auth)
        data = r.json()
        if isinstance(data, types.DictType):
            return data.update(next_data)
        if isinstance(data, types.ListType):
            return data + next_data
    return r.json()


def get_pull_request_comments(pull_request):
    #repo_owner, repo_name, pull_request_number, file_to_diff = pull_request
    url = "https://api.github.com/repos/%s/%s/pulls/%s/comments" % \
            (pull_request.repo_owner,
             pull_request.repo_name,
             pull_request.pr_number)
    # I was hoping this would render the markdown to text, but that
    # does not appear to be the case.
    #headers = {'Accept': 'application/vnd.github.v3.text+json',
    #           'User-Agent': 'git-comments via python requests'}

    r_comments = get_url(url, auth=get_auth())
    return r_comments


def format_comment_body(comment):
    body_text_gfm = comment['body']
    body_text_md = gfm(body_text_gfm)
    body_text_html = markdown.markdown(body_text_md)
    body_text_lines = (BeautifulSoup(body_text_html).findAll(text=True))

    body_text = "\n".join(body_text_lines)
    return body_text


def show_pull_request_comments(comments, pull_request):
    # unified diff chunk header
    # lets sort the comments by path
    # we probably want to eventually subsort on computed line offset,
    # and to put the comments in order they were added
    #  so we probably need to figure out the comments and store
    # the order based on the computed stuff, then walk over them
    # again and display
    # sort by file path
    comments.sort(key=operator.itemgetter('path'))
    for comment in comments:
        comment_line = find_comment_line(comment, pull_request)
        if comment_line is None:
            # no comment applies
            continue

        body_text = format_comment_body(comment)
        # this is less broken now
        # FIXME: this is broken. The position/original_postion in the review
        # comment json is not the position in the patched file, but just the
        # position in the diff hunk itself.
        #
        # We should be able to parse the diff enough to get the starting offset
        # of the diff, and figure out the right offset for the comment from
        # there. hopefully just counting newlines and +/-'s can get us close
        # enough
        print "%s:%s:%s:pr%s: %s" % (comment['path'], comment_line,
                                     comment['user']['login'], pull_request.pr_number,
                                     body_text)

#FIXME, turn on basic auth just to not get rate limited so
# much for testing. Need to add oauth support
# also,
#def get_auth():
def read_user_cfg():
    global cfg
    cfg = ConfigParser.ConfigParser()
    cfg_file = os.path.expanduser("~/.github-comments")
    if not os.access(cfg_file, os.R_OK):
        return None
    cfg.read(cfg_file)
    return cfg

def get_auth():
    global cfg
    if cfg is None:
        print "no user cfg, using basic auth"
        return None
    user = cfg.get("main", "username")
    password = cfg.get("main", "password")
    return user, password


def main():
    repo_name = None
    repo_owner = None

    read_user_cfg()

    pull_requests = PullRequestList()

    # clearly not the most rebust arg handling yet
    if len(sys.argv) > 1:
        try:
            repo_owner = sys.argv[1]
            repo_name = sys.argv[2]
            pull_request_number = sys.argv[3]
            pull_requests.add_by_number(repo_owner,
                                        repo_name,
                                        pull_request_number)
        except Exception:
            print "usage: github-comments repo_name pr_number"
            raise
    else:
        # well then, let's guess!

        # local branch name
        local_ref_name = get_branch_ref()

        # look up the merge ref, if we dont have one, skip it.
        # we could probably take some guesss...
        remote_ref_name = get_remote_branch_ref(local_ref_name)

        # lets find all the github repo's this could be a branch of,
        # ignoring multiple remote names for the same repo
        github_repos = find_github_repos()

        for github_repo in github_repos:
            repo_owner, repo_name = github_repo

            # does it make sense to support multiple per requests per
            # branch? Suppose you can push a branch to a fork, and then
            # make multiple pull requests to different upstreams?
            pull_requests.find_prs_for_ref(repo_owner, repo_name,
                                           remote_ref_name)

    # see list of pull commits, including info about the ref of the branch
    # it was created for.
    # https://api.github.com/repos/candlepin/subscription-manager/pulls?open

    # set errorformat='%f:%l:%m,%E%f:%l:%m,%-Z%^%$

    if not pull_requests.prs:
        sys.stderr.write("no open pull requests found\n")
        sys.exit()

    for pull_request in pull_requests.prs:
        pr_comments = get_pull_request_comments(pull_request)
        show_pull_request_comments(pr_comments, pull_request)

if __name__ == "__main__":
    main()
